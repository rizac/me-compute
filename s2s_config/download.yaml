# =======================================================
# Stream2segment config file to tune the download routine
# =======================================================

# NOTE: This file is written in YAML syntax, which uses Python-style indentation to
# indicate nesting, keep it in mind when editing. You can also use a more compact format
# that uses [] for lists and {} for maps/objects. For info see:
# http://docs.ansible.com/ansible/latest/YAMLSyntax.html


# Database URL where to save data (currently supported are SQLite and Postgres).
# We suggest sqlite for small to medium data sizes or enough system RAM (as a rule of
# thumb: less than a million segments, and/or more than 8GB of RAM) and postgres
# otherwise (note that with postgres, the database must have been created beforehand).
# If sqlite, just write the path to your local file prefixed with 'sqlite:///' (e.g.,
# 'sqlite:////home/myfolder/db.sqlite'): non-absolute paths will be relative to the
# config file path.
# If non-sqlite, the syntax is: dialect+driver://username:password@host:port/database
# E.g.: postgresql://smith:Hw_6,@mymachine.example.org/mydb
# (for info see: http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls)
dburl: 'postgresql://me:<password>@localhost/me_06_2020'  # NOTE: will be overwritten in the Me program

# Limit to events / data centers / station / channels on or after the specified start time. Specify a date or
# date-time in iso-format or an integer >=0 to denote the number of days before today at midnight.
# Example: start=1 and end=0 => fetch events occurred yesterday
starttime: 2006-01-01T00:00:00

# Limit to events / data centers / station / channels on or before the specified end time. Specify a date or
# date-time in iso-format or an integer >=0 to denote the number of days before today at midnight.
# Example: start=1 and end=0 => fetch events occurred yesterday
endtime: 2016-12-25T00:00:00


# =======
# Events: https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.1.pdf#page=14
# =======

# The event web service url to use. Supply a *full* url (up to and not including
# the first query character '?') or a path to a local file.
# The events list returned by the url or in the supplied file must be formatted as specified
# in https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.1.pdf#page=16
# or as isf (http://www.isc.ac.uk/standards/isf/download/isf.pdf), although the latter
# has limited support in this program (e.g., comments are not supported. Use at your own risk).
# Implementation details: 1. You can also type one of the following shortcut strings:
# "emsc": http://www.seismicportal.eu/fdsnws/event/1/query
# "isc": http://www.isc.ac.uk/fdsnws/event/1/query
# "iris": http://service.iris.edu/fdsnws/event/1/query
# "ncedc": http://service.ncedc.org/fdsnws/event/1/query
# "scedc": http://service.scedc.caltech.edu/fdsnws/event/1/query
# "usgs": http://earthquake.usgs.gov/fdsnws/event/1/query.
# 2. If providing an event list file, the file name (not the full path) will be used
# as catalog identifier: renaming the file and downloading again on the same database
# will result in the events and their segments being saved twice
eventws: 'http://geofon.gfz-potsdam.de/fdsnws/event/1/query'

# Limit to events with a latitude larger than or equal to the specified minimum.
# This parameter is ignored if missing, null, or 'eventws' is given as file path
minlatitude:

# Limit to events with a latitude smaller than or equal to the specified maximum
# This parameter is ignored if missing, null, or 'eventws' is given as file path
maxlatitude:

# Limit to events with a longitude larger than or equal to the specified minimum
# This parameter is ignored if missing, null, or 'eventws' is given as file path
minlongitude:

# Limit to events with a longitude smaller than or equal to the specified maximum
# This parameter is ignored if missing, null, or 'eventws' is given as file path
maxlongitude:

# Limit to events with depth more than the specified minimum.
# This parameter is ignored if missing, null, or 'eventws' is given as file path
mindepth:

# Limit to events with depth less than the specified maximum
# This parameter is ignored if missing, null, or 'eventws' is given as file path
maxdepth:

# Limit to events with a magnitude larger than the specified minimum
# This parameter is ignored if missing, null, or 'eventws' is given as file path
minmagnitude:

# Limit to events with a magnitude smaller than the specified maximum
# This parameter is ignored if missing, null, or 'eventws' is given as file path
maxmagnitude: null

# Additional event web search parameters. For info, see
# https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.1.pdf#page=14
# (parameters with support 'Optional' are not guaranteed to work). Note that the 'format' parameter,
# if missing, will be inferred (in most cases it defaults to 'text').
# Implementation details: The parameter is empty by default, uncomment the lines below
# or insert new ones. Remember that this is a YAML file, pay attention to indentation. 
eventws_params:
  # lat: 47.0
  # lon: 4.0
  # minradius: 17.0
  # maxradius: 21.0


# ====================
# Stations / Channels: https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.1.pdf#page=10
# ====================

# Limit the search to the specified channels (if missing, defaults to '*', i.e.: accept
# all channels). Wildcards '?' and '*' are recognized
# (https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf), as well as the
# operator '!' placed as first character to indicate logical NOT. Example: "!B*,BBB"
# accepts all channels NOT starting with "B" OR the channel "BBB"
# Implementation details: 'cha' or 'channels' are also valid names for the parameter. You
# can also specify a list/array of strings in yaml format instead of comma-separated
# strings. E.g., these are equivalent:
# channels: "A,B"
# cha: [ "A" , "B" ]
# channel:
#  - "A"
#  - "B"
channel:
 - "BHZ"
 
# Limit the search to the specified networks (see 'channel' parameter for details).
# Implementation details: 'net' or 'networks' are also valid names for the parameter.
network: '*'

# Limit the search to the specified stations (see 'channel' parameter for details).
# Implementation details: 'sta' or 'stations' are also valid names for the parameter.
station: '*'

# Limit the search to the specified locations (see 'channel' parameter for details).
# Implementation details: 'loc' or 'locations' are also valid names for the parameter.
location: '*'

# Limit the search to channels with at least the following sample rate (in Hz).
# The relative segments will *most likely* (but not always) match the channel sample rate.
# Set to 0 or negative number to ignore the sampling rate
min_sample_rate: 1

# Update segments metadata, i.e. when fetching stations and channels, save them
# to the database overwriting already saved stations and channels, if present.
# When false, only new stations and channels will be saved to the database.
# On a subsequent download, you can also provide "only" as value (without quotes)
# to update metadata only, skipping events and waveform download: in this case the *only*
# parameters used will be 'dataws' (to get the station web service(s)) and 'inventory'
# (to optionally re-download and save all station inventories).
update_metadata: false

# Download station inventories (xml format). When true, you can
# control whether or not to overwrite already saved inventories with 'update_metadata'
# (when false, update_metadata should also be false for data consistency).
# Implementation details: inventories will in any case be downloaded and saved on the database
# only for stations that have saved segments with data. 
inventory: true

# search radius: defines the criteria for selecting stations around events. It is a dict
# which can have either:
# 1) two arguments ('min', 'max') in order to select stations exactly or within 'min' and 'mag' degrees
# from each event location (min=0 is equivalent to a circular search area)
# 2) four arguments in order to select stations within a circular
# area whose radius is event's magnitude dependent:
#
#                   |
#     maxmag_radius +                oooooooooooo
#                   |              o
#                   |            o
#                   |          o
#     minmag_radius + oooooooo
#                   |
#                   ---------+-------+------------
#                         minmag   maxmag
# If minmag = maxmag = M, maxmag_radius will be used for events with magnitude >= M,
# minmag_radius otherwise
search_radius:
 #minmag: 6 # min magnitude
 #maxmag: 7 # max magnitude
 #minmag_radius: 3 # search radius for min mag (deg)
 #maxmag_radius: 3 # search radius for max mag (deg)
 min: 5  # min radius (deg)
 max: 98  # max radius (deg)


# ========================
# Data (waveform segments) https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.1.pdf#page=8
# ========================

# List of URLs for downloading waveform data (data web services). All URLs must
# be FDSN-compliant, e.g.: https://service.iris.edu/fdsnws/dataselect/1/query
# You can also type two special values: 1) "iris" (Incorporated Research Institutions for
# Seismology, shortcut for the URL above) or 2) "eida" (European Integrated Data Archive,
# shortcut for the URLs list of all EIDA data centers, or nodes). Being FDSN compliant,
# all URLs are also used to fetch automatically the stations (and channels) necessary for
# the waveforms download.
# IMPORTANT: When providing two (or more) URLs, station conflicts (e.g., the same station
# returned by both URLs) which cannot be resolved will cause the station to be discarded
# (the user will be notified in the log file) and all its available waveforms not to be
# downloaded. The program tries to resolve conflicts with a Routing service (for EIDA
# URLs) or by checking if the station URL is saved on the database from a previous
# download (thus, conflicts involving EIDA nodes have more chances to be resolved).
# Implementation details: If no station /channel could be downloaded (e.g., connection
# problems), then the requested stations and channels will be fetched from the database,
# if non-empty (otherwise the download process will stop with an error message). The EIDA
# routing service is configurable in `advanced_settings`. In the URLs below, If the URL \
# scheme - basically the prefix "http://" or "https://" - is missing, 'http://' will be
# prepended to the URL. An ending '/' or '?' will be removed from the URL, if present).
dataws:
 - 'eida'
 - 'iris'

# The model to asses the travel time of a wave from the event location to a station
# location, which will be used to get the segment arrival time (travel time +
# event time) and eventually the segment time window to download (see also `timespan`).
# Type one of the 4 built-in models:
#   ak135_ttp+: ak135 model for all ttp+ phases (P wave arrivals)
#   ak135_tts+: ak135 model for all tts+ phases (S wave arrivals)
#   iasp91_ttp+: iasp91 model for all ttp+ phases (P wave arrivals)
#   iasp91_tts+: iasp91 model for all tts+ phases (S wave arrivals)
# Implementation details: the models above are grids of pre-computed travel times
# obtained from the corresponding model. The grids allow to speed up significantly the
# computation introducing a negligible interpolation error (roughly in the order of
# few milliseconds and never exceeding 0.5s). Disclaimer: you can also create your own
# grid file and put its path here. However, the procedure is not maintained anymore, it
# might have bugs. For info type `python stream2segment/traveltimes/ttcreator.py --help`
traveltimes_model: 'ak135_ttp+'

# The segment's time span (i.e., the data time window to download): specify two positive
# floats denoting the minutes to account for before and after the calculated arrival
# time. Note that 3.5 means 3 minutes 30 seconds, and that each segment window will be
# eventually rounded to the nearest second.
# Implementation details: the rounding is necessary to avoid floating point errors when
# checking for segments to re-download because of a changed window.
timespan:
 - 5.0 # start time of the waveform segment to download, in minutes *before* the calculated arrival time.
 - 10.0 # end time of the waveform segment to download, in minutes *after* the calculated arrival time

# Credentials to download restricted data. When null, missing or "", only open waveforms
# will be downloaded. When provided, it can be either a list of two strings (username and
# password), or, for EIDA node(s), a string denoting the path of a token file (to get a
# token, see https://geofon.gfz-potsdam.de/waveform/archive/auth/auth-overview.php)
# IMPORTANT: You SHOULD NOT perform massive, time-consuming downloads when fetching
# restricted data: first, it makes no sense: credentials are valid only for the
# organization emitting them (thus there must be only one item in `dataws`) and second,
# credentials might have an expiration time (e.g., roughly few hours for EIDA tokens).
# Thus, try narrowing the search: e.g., shorter time bounds, network(s) or station(s) of
# interest only. Have a look also at `max_concurrent_downloads` in `advanced_settings` as
# in this case you might want to improve download efficiency over execution speed.
# Implementation details: restricted segments previously downloaded with no credentials
# (thus, with no waveform data) will be always re-downloaded ignoring all 'retry'
# settings. If you need to provide username and password, remember indentation in YAML
# (see parameter `timespan`). If you provide a token with a non-absolute path, its path
# will be relative to the config file path
restricted_data: ""

# Try to download again already saved segments with no waveform data because not found
# in the response. This is NOT the case when the server returns no data with an appropriate
# 'No Content' message, but when a successful multi-segment request returns some but not all
# requested segments: missing segments will then belong to the "not found" category
retry_seg_not_found: true

# Try to download again already saved segments with no waveform data because of a
# general url error (e.g., no internet connection, timeout, ...)
retry_url_err: true

# Try to download again already saved segments with no waveform data because the response was
# malformed, i.e. not readable as MiniSeed
retry_mseed_err: false

# Try to download again already saved segments with no waveform data because of a client error
# (response code in [400,499])
retry_client_err: true

# Try to download again already saved segments with no waveform data because of a server error
# (response code in [500,599])
retry_server_err: true

# Try to download again already saved segments with no waveform data because the response data
# was completely outside the requested time span (see 'timespan' for details)
retry_timespan_err: true


# =====================================
# Advanced settings (for experts only) 
# =====================================

advanced_settings:
 # the routing service used to fetch the eida nodes and relative network/stations
 routing_service_url: "http://www.orfeus-eu.org/eidaws/routing/1/query"
 # size (in bytes) of each block of data requested when downloading until no data is available.
 # This setting holds for any kind of data downloaded (event, waveform or station metadata)
 # If 0 or negative, all data will be read in a single call (if 0, it will be converted to -1).
 download_blocksize: 1048576  # = 1024*1024
 # Maximum number of concurrent (roughly speaking, simultaneous) downloads allowed. The
 # default (null) means 'set it automatically' (usually between 4 and 8, depending on the
 # number of CPUs in the system), whereas 1 disables concurrency and downloads all data
 # in series (i.e., sequentially).
 # We recommend to leave this parameter to null because it improves significantly the
 # execution speed, and to set it to 1, 2, or any small number of your choice) only in
 # more targeted, less "massive" downloads, e.g.:
 # a) when fetching restricted data (see `restricted_data` parameter)
 # b) when retrying to fetch data from a specific datacenter (see `dataws` parameter)
 #    which reported many download errors suggesting to "slow down", e.g. "Service
 #    Unavailable" (code 503) or "Too Many Requests" (code 429). You can inspect errors
 #    in the summary table printed after all segments are downloaded, or via the command
 #    `s2s utils dreport`
 max_concurrent_downloads: 2
 # max time to wait (in seconds) for a single request while downloading events
 e_timeout: 120
 # max time to wait (in seconds) for a single request while downloading stations+channel metadata
 s_timeout: 120
 # max time to wait (in seconds) for a single request while downloading an inventory in xml format
 i_timeout: 60
 # max time to wait (in seconds) for a single request while downloading waveform data
 w_timeout: 30
 # the buffer size used when writing items (stations, segments, events, ...) to database.
 # Increasing this number usually speeds speed up database IO operations (also, we experienced
 # performance degradations when this number is below the range [30, 50]) but increases the memory
 # consumption. Note also that if a single item in the buffer cannot be inserted or updated
 # (e.g., integrity errors), all subsequent buffer items will also be discarded
 db_buf_size: 100
