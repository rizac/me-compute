# ====================================================
# Stream2segment configuration file / download routine
# ====================================================

# This file is written in YAML syntax. For info see: http://docs.ansible.com/ansible/latest/YAMLSyntax.html


# Database URL where to save downloaded data, either SQLite (local file db) or Postgres
# (local or remote db. With postgres, the database must have been created beforehand). We
# suggest sqlite for small to medium data or enough system RAM (as a rule of thumb:
# less than a million segments, and/or more than 8GB of RAM) and postgres otherwise.
# For info see: http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls
dburl: sqlite:///./db.sqlite

# Limit to events / data centers / station / channels on or after the specified start
# time. Specify an ISO-formatted date or date-time string, or an integer >=0 to denote
# the number of days before today at midnight, e.g., start=1 and end=0 means: fetch
# events occurred yesterday
starttime: 0

# Limit to events / data centers / station / channels on or before the specified end
# time. Specify an ISO formatted date or date-time string, or an integer >=0 to denote
# the number of days before today at midnight, e.g., start=1 and end=0 means: fetch
# events occurred yesterday
endtime: -1


# =======
# Events: https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf#page=14
# =======

# The event catalog in form of URL or local file path.
# The events list returned by the URL or in the supplied file must be in FDSN format
# (https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf#page=16) or ISF format
# (http://www.isc.ac.uk/standards/isf/download/isf.pdf), although the latter has limited
# support (e.g. comments are not recognized and might break): use it at your own risk.
# IMPORTANT: when providing a file, the file name will be used as catalog identifier:
# renaming the file and downloading again on the same database will result in the events
# and their segments being saved twice, most likely unnecessarily.
# You can also type these shortcut strings instead of URLs:
# "emsc": http://www.seismicportal.eu/fdsnws/event/1/query
# "isc": http://www.isc.ac.uk/fdsnws/event/1/query
# "iris": http://service.iris.edu/fdsnws/event/1/query
# "ncedc": http://service.ncedc.org/fdsnws/event/1/query
# "scedc": http://service.scedc.caltech.edu/fdsnws/event/1/query
# "usgs": http://earthquake.usgs.gov/fdsnws/event/1/query.
events_url: http://geofon.gfz-potsdam.de/fdsnws/event/1/query

# NOTE: all event parameters below are ignored if missing, empty, null, or
# 'events_url' is  given as file path

# Limit to events with a latitude larger than or equal to the specified minimum.
minlatitude: null

# Limit to events with a latitude smaller than or equal to the specified maximum
maxlatitude: null

# Limit to events with a longitude larger than or equal to the specified minimum
minlongitude: null

# Limit to events with a longitude smaller than or equal to the specified maximum
maxlongitude: null

# Limit to events with depth more than the specified minimum
mindepth: 0

# Limit to events with depth less than the specified maximum
maxdepth: null

# Limit to events with a magnitude larger than the specified minimum
minmagnitude: null

# Limit to events with a magnitude smaller than the specified maximum
maxmagnitude: null

# Event parameters in addition to those already provided above. These are usually for
# refined searches and can be provided as YAML Mapping of indented "param: value" pairs.
# For info see https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf#page=14
# Note that parameters with support 'Optional' at the link above are not guaranteed to
# work. The 'format' parameter will be ignored as it is automatically set by the program.
events_extra_params:
  magnitudetype: 'Mw'


# ====================
# Stations / Channels: https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf#page=10
# ====================

# NOTE: the station URL(s) are configurable in `data_url` (see below). When
# providing several URLs, if the same station code is returned by more than one URL, the
# program will try to infer the correct one by means of a Routing service for EIDA URLs
# (see `advanced_settings`) or by querying the station URL to the database, if any. If
# none of the operations is successful, the station will be discarded and all its
# available waveforms not downloaded (see log file in case).
# Implementation details: in case of connection problems where no station can be fetched,
# then the requested stations (and channels) will be fetched from the database, if any.

# Limit the search to the specified channels (if missing, defaults to '*', i.e. fetch all
# channels). For info see https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf.
# You can also filter out specific channels by placing the special character "!" in front
# of them. This is a non standard FDSN syntax implemented in this program only, and thus
# will be applied after the list of channels is obtained. Consequently, pay attention to
# inconsistencies such as "!B*,BHZ" that will first fetch all channels "BHZ" and then
# remove ("!") all channels starting with "B" ("B*"), causing no channel to be selected.
# Implementation details: You can also specify a YAML sequence of strings instead of
# comma-separated strings. E.g., these are equivalent:
# channels: "A,B"
# cha: [ "A" , "B" ]
# channel:
#  - "A"
#  - "B"
channel:
 - BHZ
 
# Limit the search to the specified networks (see 'channel' parameter for details)
network: '*'

# Limit the search to the specified stations (see 'channel' parameter for details)
station: '*'

# Limit the search to the specified locations (see 'channel' parameter for details)
location: '*'

# Limit the search to channels with at least the following sample rate (in Hz).
# The relative segments will most likely (but not always) match the channel sample rate.
# Set to 0 or negative number to ignore the sampling rate
min_sample_rate: 1

# Update segments metadata, i.e., overwrite the data of already saved stations and
# channels, such as e.g., the channels sample rate, or the station inventories (see also
# ‘inventory’ parameter)
update_metadata: false

# Download station inventories (xml format). Already saved inventories will be
# overwritten according to ‘update_metadata’
# Implementation details: inventories will in any case be downloaded and saved on the
# database only for stations that have saved segments with waveform data
inventory: true

# search radius: defines the criteria for selecting stations around events. It is a dict
# which can have either:
# 1) two arguments ('min', 'max'), to select stations within 'min' and 'max' deggrees
# (endpoints included) from each event location (type min=0 for a circular search area)
# 2) four arguments, to select stations within a circular area whose radius is dependent
# on the event magnitude:
#
#                   |
#     maxmag_radius +                oooooooooooo
#                   |              o
#                   |            o
#                   |          o
#     minmag_radius + oooooooo
#                   |
#                   ---------+-------+------------
#                         minmag   maxmag
# If minmag = maxmag = M, `maxmag_radius` will be used for events with magnitude >= M,
# `minmag_radius` otherwise
search_radius:
  min: 5  # min radius (deg)
  max: 98  # max radius (deg)
  # minmag: 6 # min magnitude
  # maxmag: 7 # max magnitude
  # minmag_radius: 3 # search radius for min mag (deg)
  # maxmag_radius: 3 # search radius for max mag (deg)


# ========================
# Data (waveform segments) https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.2.pdf#page=8
# ========================

# List of URLs for downloading waveform data. All URLs must be
# FDSN-compliant (e.g.: https://service.iris.edu/fdsnws/dataselect/1/query). You can also
# type two special values: 1) "iris" (Incorporated Research Institutions for Seismology),
# shortcut for the URL above or 2) "eida", shortcut for several nodes - or data centers -
# of the European Integrated Data Archive. Being FDSN compliant, all URLs are also used
# to fetch automatically the stations and channels necessary for the waveforms download
data_url:
  - eida
  - iris

# The segment's time span (i.e., the data time window to download): specify two
# floats denoting the minutes to account for before and after the calculated arrival
# time (negative numbers are allowed). Note that 3.5 means 3 minutes 30 seconds, and
# that each segment window will be eventually rounded to the nearest second.
# Implementation details: the rounding is necessary to avoid floating point errors when
# checking for segments to re-download because of a changed window.
timespan:
 - 5.0 # start of the waveform segment, in minutes *before* the calculated arrival time.
 - 10.0 # end of the waveform segment, in minutes *after* the calculated arrival time

# Credentials to download restricted data. When null, missing or "", only open waveforms
# will be downloaded. When provided, it can be either a list of two strings (username and
# password), or, for EIDA node(s), a string denoting the path of a token file (to get a
# token, see https://geofon.gfz-potsdam.de/waveform/archive/auth/auth-overview.php)
# IMPORTANT: You SHOULD NOT perform massive, time-consuming downloads when fetching
# restricted data: first, it makes no sense: credentials are valid only for the
# organization emitting them (thus there must be only one item in `data_url`) and second,
# credentials might have an expiration time (e.g., roughly few hours for EIDA tokens).
# Thus, try narrowing the search: e.g., shorter time bounds, network(s) or station(s) of
# interest only (for advanced users: see also at `max_concurrent_downloads` in
# `advanced_settings`).
# Implementation details: restricted segments previously downloaded with no credentials
# (thus, with no waveform data) will be always re-downloaded ignoring all 'retry'
# settings. If you need to provide username and password, remember indentation in YAML
# (see parameter `timespan`). If you provide a token with a non-absolute path, its path
# will be relative to the config file path
restricted_data: ""

# Retry already downloaded segments if the database reports that the previous attempt was
# unsuccessful because no data could be found. This typically happens when a single
# request of several waveform segments to a server gets in response only some of them,
# with no clue about the missing ones, which are then "marked" as "not found"
retry_seg_not_found: true

# Retry already downloaded segments if the database reports that the previous attempt was
# unsuccessful because of a general URL error (e.g., no internet connection, timeout, ...)
retry_url_err: true

# Retry already downloaded segments if the database reports that the previous attempt was
# unsuccessful because the waveform data was malformed, i.e. is not readable as MiniSeed
retry_mseed_err: false

# Retry already downloaded segments if the database reports that the previous attempt was
# unsuccessful because of a client (i.e., stream2segment) request error
retry_client_err: true

# Retry already downloaded segments if the database reports that the previous attempt was
# unsuccessful because of a server (see `data_url`) response error
retry_server_err: true

# Retry already downloaded segments if the database reports that the previous attempt was
# unsuccessful because received data was completely outside the requested time window
# (see 'timespan' for details)
retry_timespan_err: true


# =====================================
# Advanced settings (for experts only) 
# =====================================

advanced_settings:
 # Maximum number of concurrent / simultaneous downloads allowed. The default (null) lets
 # the program optimize this number depending on the computer CPU and data centers.
 # We recommend to leave this parameter to null and set it to 1 (max 2) only in case you
 # need to maximize download efficiency over speed, e.g.:
 # a) when fetching restricted data (see `restricted_data` parameter)
 # b) when retrying to fetch data from a specific datacenter which reported many download
 #    errors suggesting to "slow down", e.g. "Service Unavailable" (code 503) or
 #    "Too Many Requests" (code 429). You can inspect errors in the summary table printed
 #    after all segments are downloaded, or via the command `s2s dl report`
 max_concurrent_downloads: null
 # Routing service used to fetch the EIDA nodes and relative network/stations
 routing_service_url: http://www.orfeus-eu.org/eidaws/routing/1/query
 # Max time to wait (in seconds) for a single request while downloading events
 e_timeout: 120
 # Max time to wait (in seconds) for a single request while downloading stations+channel
 # metadata
 s_timeout: 120
 # Max time to wait (in seconds) for a single request while downloading an inventory in
 # XML format
 i_timeout: 60
 # Max time to wait (in seconds) for a single request while downloading waveform data
 w_timeout: 30
 # Size (in bytes) of each block of data requested when downloading. It applies to any
 # kind of data (event, waveform or station metadata). If 0, it will be converted to -1.
 # If negative, all data will be always read in a single call and one block.
 download_blocksize: 1048576  # = 1024*1024
 # The buffer size used when writing (inserting or updating) database data, in number of
 # segments. Increasing this number speeds up the download (we experienced performance
 # degradation when it's below the range [30, 50]) but increases the memory consumption.
 # Consider also that a single database error while writing a segment will unfortunately
 # affect all buffer segments, which must all be discarded
 db_buf_size: 100
 # The model to asses the travel time of a wave from the event location to a station
 # location, which will be used to get the segment arrival time (travel time +
 # event time) and eventually the segment time window to download (see also `timespan`).
 # Type one of the 4 built-in models:
 #   ak135_ttp+: ak135 model for all ttp+ phases (P wave arrivals)
 #   ak135_tts+: ak135 model for all tts+ phases (S wave arrivals)
 #   iasp91_ttp+: iasp91 model for all ttp+ phases (P wave arrivals)
 #   iasp91_tts+: iasp91 model for all tts+ phases (S wave arrivals)
 # Implementation details: the models above are grids of pre-computed travel times
 # obtained from the corresponding model. The grids allow to speed up significantly the
 # computation introducing a negligible interpolation error (roughly in the order of
 # few milliseconds and never exceeding 0.5s). Disclaimer: you can also create your own
 # grid file and put its path here. However, the procedure is not maintained anymore, use
 # at your risk. For info type `python stream2segment/traveltimes/ttcreator.py --help`
 traveltimes_model: 'ak135_ttp+'